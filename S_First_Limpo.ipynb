{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNhAkaLvzLbZ",
        "outputId": "89d57b0c-c87c-494e-d841-c013fcb3b31c"
      },
      "outputs": [],
      "source": [
        "from keras.utils import image_dataset_from_directory\n",
        "import tensorflow as tf\n",
        "train_dir_1 = 'trainning/train1'\n",
        "train_dir_2 = 'trainning/train2'\n",
        "train_dir_3 = 'trainning/train3'\n",
        "validation_dir = 'train4' # Validation\n",
        "train_dir_5 = 'trainning/train5'\n",
        "test_dir = 'test'\n",
        "\n",
        "trainning = [train_dir_1, train_dir_2,train_dir_3,train_dir_5]\n",
        "\n",
        "train_dir = train_dir_2\n",
        "IMG_SIZE = 32 # 32x32\n",
        "\n",
        "# image_dataset_from_directory with labels=\"inferred\" for \n",
        "# getting the images in the subdirectories and translating the subdirectory as a class \n",
        "# of type categorical\n",
        "#train_dataset = image_dataset_from_directory(train_dir,image_size=(IMG_SIZE, IMG_SIZE),batch_size=32, labels=\"inferred\", label_mode=\"categorical\")\n",
        "test_dataset = image_dataset_from_directory(test_dir,image_size=(IMG_SIZE, IMG_SIZE), labels=\"inferred\",label_mode=\"categorical\")\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,image_size=(IMG_SIZE, IMG_SIZE), labels=\"inferred\",label_mode=\"categorical\")\n",
        "\n",
        "train_dataset = tf.data.Dataset\n",
        "\n",
        "for i in trainning:\n",
        "    if i == trainning[0]:\n",
        "        train_dataset = image_dataset_from_directory(i, image_size=(IMG_SIZE, IMG_SIZE), labels=\"inferred\", label_mode=\"categorical\")\n",
        "        continue\n",
        "    train_dataset = train_dataset.concatenate( image_dataset_from_directory(i, image_size=(IMG_SIZE, IMG_SIZE), labels=\"inferred\", label_mode=\"categorical\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaWnxsbZWk5e"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "IMG_SIZE = 32\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Output layer\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models_S/S_without_DA_First.h5', monitor='val_loss', verbose=0,\n",
        "    save_best_only=True, mode='min'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=5, verbose=1, mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "rl = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=4,\n",
        "    verbose=0,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "\n",
        "# batch size 32\n",
        "# Test loss: 0.6775595545768738\n",
        "# Test accuracy: 0.8391000032424927\n",
        "\n",
        "# batch size 64\n",
        "# Test loss: 0.693570613861084\n",
        "# Test accuracy: 0.8421000242233276\n",
        "\n",
        "# batchsize 128\n",
        "# Test loss: 0.7256516814231873\n",
        "# Test accuracy: 0.8317000269889832\n",
        "\n",
        "# sem BatchNormalization\n",
        "#Test loss: 0.7569888234138489\n",
        "# Test accuracy: 0.8009999990463257\n",
        "\n",
        "# sem Droupout\n",
        "#Test loss: 1.2996251583099365\n",
        "#Test accuracy: 0.7465000152587891\n",
        "\n",
        "\n",
        "\n",
        "#64 BATCH_SIZE - pacience 10\n",
        "\n",
        "# Epoch 102: early stopping\n",
        "# 313/313 [==============================] - 1s 3ms/step - loss: 0.7004 - accuracy: 0.8350\n",
        "# Test loss: 0.7004380226135254\n",
        "# Test accuracy: 0.8349999785423279\n",
        "\n",
        "#128\n",
        "# Test loss: 0.7256516814231873\n",
        "# Test accuracy: 0.8317000269889832"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "collapsed": true,
        "id": "hULJZaAZxXn_",
        "outputId": "450370ed-8dde-4b67-a6d3-d98477a5b7d2"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[checkpoint, early_stopping, rl]\n",
        "  )\n",
        "\n",
        "\n",
        "# Avaliar o modelo (com o teste)\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lPeG3hSZGTg"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "        [layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),])\n",
        "\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode='nearest',\n",
        "    # # shear_range=0.2,\n",
        "    # # zoom_range=0.2,\n",
        "    # # horizontal_flip=True,\n",
        "    # # fill_mode='nearest',\n",
        "    # # channel_shift_range=0.2,\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Output layer\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# compilar o modelo\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models_S/S_with_DA_First.h5', monitor='val_loss', verbose=0,\n",
        "    save_best_only=True, mode='min'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=4, verbose=1, mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "learning_rate = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=4,\n",
        "    verbose=0,\n",
        "    mode=\"min\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history2 = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[checkpoint, early_stopping, rl]\n",
        "  )\n",
        "\n",
        "\n",
        "# Avaliar o modelo (com o teste)\n",
        "test_loss, test_accuracy = model2.evaluate(test_dataset)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SraYxQyEGmrI"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/best_modelS_WITHOUT_64.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bISQOj0R9QNJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# usar para instalar...: pip install scikit-learn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# to install IPython, use: pip install ipython\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h4LHX-3Q2BB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Definir nomes das classes\n",
        "class_names = {\n",
        "    0: \"Airplane\",\n",
        "    1: \"Automobile\",\n",
        "    2: \"Bird\",\n",
        "    3: \"Cat\",\n",
        "    4: \"Deer\",\n",
        "    5: \"Dog\",\n",
        "    6: \"Frog\",\n",
        "    7: \"Horse\",\n",
        "    8: \"Ship\",\n",
        "    9: \"Truck\"\n",
        "}\n",
        "\n",
        "# Prever para todo o conjunto de teste\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    predictions = model.predict(x)\n",
        "    y_pred.extend(np.argmax(predictions, axis=1))\n",
        "    y_true.extend(np.argmax(y, axis=1))\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names.values(), yticklabels=class_names.values())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Relatório de classificação\n",
        "class_report = classification_report(y_true, y_pred, target_names=class_names.values())\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "76p03DBx8DXa",
        "outputId": "39cf1385-1e3c-4b01-ea9c-277d0e8ebb6f"
      },
      "outputs": [],
      "source": [
        "def graph(history, title):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "graph(history, \"Modelo S sem Data Augmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "F2fSuF6NUe3K",
        "outputId": "b6952995-031c-4dbc-cc3d-4889ee29791a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have already trained your model and obtained predictions and true labels\n",
        "# Example lists for demonstration\n",
        "\n",
        "\n",
        "# Extract images and labels from test_dataset\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    test_images.append(images.numpy())  # Assuming you convert images to numpy arrays\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "test_images = np.concatenate(test_images)\n",
        "test_labels = np.concatenate(test_labels)\n",
        "\n",
        "# Normalize the images to [0, 1]\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "\n",
        "# Display images with predictions and true labels\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)  # Display the ith image\n",
        "    predicted_label = class_names[y_pred[i]]\n",
        "    true_label = class_names[y_true[i]]\n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "    plt.xlabel(f'Pred: {predicted_label} \\n True: {true_label}', color=color)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GlsFGHn3Bsvy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Assuming you have defined your test_dataset and model somewhere\n",
        "\n",
        "# Get the first image from test_dataset\n",
        "first_batch = next(iter(test_dataset))  # Get the first batch from the dataset\n",
        "first_image = first_batch[0][0]  # Extract the first image from the batch\n",
        "\n",
        "# Display the original image\n",
        "plt.imshow(first_image.numpy().astype(\"uint8\"))\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Preprocess the image for visualization\n",
        "img = first_image.numpy()\n",
        "img = np.expand_dims(img, axis=0)  # Now img has shape (1, 32, 32, 3)\n",
        "\n",
        "def visualize_filters(model, img):\n",
        "    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name or 'pool' in layer.name]\n",
        "\n",
        "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "    activations = activation_model.predict(img)\n",
        "\n",
        "    layer_names = [layer.name for layer in model.layers if 'conv' in layer.name or 'pool' in layer.name]\n",
        "\n",
        "    for layer_name, layer_activation in zip(layer_names, activations):\n",
        "        n_features = layer_activation.shape[-1]\n",
        "        size = layer_activation.shape[1]\n",
        "\n",
        "        n_cols = n_features // 16  # Number of columns in the grid\n",
        "        display_grid = np.zeros((size * n_cols, size * 16))\n",
        "\n",
        "        for col in range(n_cols):\n",
        "            for row in range(16):\n",
        "                channel_image = layer_activation[0, :, :, col * 16 + row]\n",
        "                channel_image -= channel_image.mean()\n",
        "                channel_image /= (channel_image.std() + 1e-5)\n",
        "                channel_image *= 64\n",
        "                channel_image += 128\n",
        "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "                display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "# Visualize filters for the model and the first image\n",
        "visualize_filters(model, img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Ab_w1I-OD2sT",
        "outputId": "9ad716bf-81e6-459e-b0ca-d449db255a93"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "# Assuming test_dataset and model are already defined\n",
        "\n",
        "random_index = random.randint(0, 500)\n",
        "\n",
        "first_batch = next(iter(test_dataset))  # Get the first batch from the dataset\n",
        "img = first_batch[0][0]  # Extract the first image from the batch\n",
        "\n",
        "img_array = img.numpy()\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Now img_array has shape (1, 32, 32, 3)\n",
        "\n",
        "plt.imshow(img_array[0].astype(\"uint8\"))  # Display the original image\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "last_conv_layer_name = 'conv2d_1'  # Replace with your actual last conv layer name\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "plt.matshow(heatmap)\n",
        "plt.title('Grad-CAM Heatmap')\n",
        "plt.show()\n",
        "\n",
        "def superimpose_heatmap(img, heatmap, alpha=0.4):\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap * alpha + img\n",
        "    return np.uint8(superimposed_img)\n",
        "\n",
        "# Convert img_array to (32, 32, 3) for superimpose_heatmap function\n",
        "img_for_superimpose = img_array[0].astype(\"uint8\")\n",
        "\n",
        "superimposed_img = superimpose_heatmap(img_for_superimpose, heatmap)\n",
        "\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title('Image with Grad-CAM Heatmap')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "L4Mw4cX-FE35",
        "outputId": "468564b3-f3b2-4170-c37e-2aff44a17b6e"
      },
      "outputs": [],
      "source": [
        "# Function to extract images and labels from a tf.data.Dataset\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def get_images_and_labels(dataset, num_samples):\n",
        "    dataset = dataset.unbatch().take(num_samples)\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img, label in dataset:\n",
        "        images.append(img.numpy())\n",
        "        labels.append(label.numpy())\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Extract images and labels from the test dataset\n",
        "x_test, y_test = get_images_and_labels(test_dataset, num_samples=1000)\n",
        "\n",
        "# Visualization function\n",
        "def visualize_feature_space(layer_name, x_data, y_data):\n",
        "    feature_extractor = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "\n",
        "    num_samples = len(x_data)\n",
        "    sample_indices = np.random.choice(len(x_data), num_samples, replace=False)\n",
        "    sample_images = x_data[sample_indices]\n",
        "\n",
        "    features = feature_extractor.predict(sample_images)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    features_reduced = pca.fit_transform(features.reshape(num_samples, -1))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(features_reduced[:, 0], features_reduced[:, 1], c=np.argmax(y_data[sample_indices], axis=1), cmap='tab10', marker='o', alpha=0.8)\n",
        "    plt.colorbar(label='Class')\n",
        "    plt.title(f'Feature Space (PCA) - Layer {layer_name}')\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have x_test and y_test as your test dataset\n",
        "layer_name = 'conv2d_1'\n",
        "visualize_feature_space(layer_name, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z4Ns3GBr89rr",
        "outputId": "07415303-f332-4638-9103-6319e91a1b21"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
